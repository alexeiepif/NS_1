{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swEDUwU6-S8x"
   },
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMJUXp5d-flR"
   },
   "source": [
    "Распознайте рукописную цифру, написанную на листе от руки.\n",
    "Последовательность шагов следующая:\n",
    "\n",
    "*   На бумаге рисуем произвольную цифру (желательно нарисовать цифру размером не\n",
    "более 5 * 5 мм и без наклона. В занятии нейронка обучалась на цифрах американских студентов. Эти цифры были написаны на тетрадных листах в клетку и имели схожий размер).\n",
    "*   Фотографируем. Загружаем фото в Collaboratory.\n",
    "*   С помощью функции image.load_img(path, target_size=(28, 28), color_mode = ‘grayscale’) загружаем картинку в переменную.\n",
    "*   С помощью функции image.img_to_array(img) преобразуем изображение в numpy-массив.\n",
    "*   Выполняем инверсию цветов, нормирование и решейп массива.\n",
    "*   Выполняем распознавание собственной рукописной цифры.\n",
    "\n",
    "Примечание: точность распознавания рукописных цифр может быть достаточно низкой, т.к. рукописные цифры после преобразований хоть и похожи на содержащиеся в базе, но могут отличаться по конфигурации, толщине линий и т.д.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739792500.344775    1063 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739792500.367755    1063 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lDCR1UFdqPUb"
   },
   "outputs": [],
   "source": [
    "# Ваше решение\n",
    "\n",
    "\n",
    "(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()\n",
    "\n",
    "x_train = x_train_org.reshape(x_train_org.shape[0], -1)\n",
    "x_test = x_test_org.reshape(x_test_org.shape[0], -1)\n",
    "\n",
    "# Преобразование x_train в тип float32 (числа с плавающей точкой) и нормализация\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "\n",
    "# Преобразование x_test в тип float32 (числа с плавающей точкой) и нормализация\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "CLASS_COUNT = 10\n",
    "\n",
    "\n",
    "# Преобразование ответов в формат one_hot_encoding\n",
    "y_train = utils.to_categorical(y_train_org, CLASS_COUNT)\n",
    "y_test = utils.to_categorical(y_test_org, CLASS_COUNT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aledonio/.cache/pypoetry/virtualenvs/global-cKEoLTwX-py3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1739792516.628542    1063 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Создание последовательной модели\n",
    "model = Sequential()\n",
    "\n",
    "# Добавление полносвязного слоя на 800 нейронов с relu-активацией\n",
    "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
    "\n",
    "# Добавление полносвязного слоя на 400 нейронов с relu-активацией\n",
    "model.add(Dense(400, activation=\"relu\"))\n",
    "\n",
    "# Добавление полносвязного слоя с количеством нейронов по числу классов с softmax-активацией\n",
    "model.add(Dense(CLASS_COUNT, activation=\"softmax\"))\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0049\n",
      "Epoch 2/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 3/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0022\n",
      "Epoch 4/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0074\n",
      "Epoch 5/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0025\n",
      "Epoch 6/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0057\n",
      "Epoch 7/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0024\n",
      "Epoch 8/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0069\n",
      "Epoch 9/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0028\n",
      "Epoch 10/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0029\n",
      "Epoch 11/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0021\n",
      "Epoch 12/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0051\n",
      "Epoch 13/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0035\n",
      "Epoch 14/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0049\n",
      "Epoch 15/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ff2591f4260>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,  # обучающая выборка, входные данные\n",
    "    y_train,  # обучающая выборка, выходные данные\n",
    "    batch_size=128,  # кол-во примеров, которое обрабатывает нейронка перед одним изменением весов\n",
    "    epochs=15,  # количество эпох, когда нейронка обучается на всех примерах выборки\n",
    "    verbose=1,\n",
    ")  # 0 - не визуализировать ход обучения, 1 - визуализировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aledonio/.cache/pypoetry/virtualenvs/global-cKEoLTwX-py3.12/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# model.save_weights(\"dz_ultra_pro.weights.h5\")\n",
    "model.load_weights(\"dz_ultra_pro.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = image.load_img(\"image_8.png\", target_size=(28, 28), color_mode='grayscale')\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = 255 - img_array\n",
    "img_array = np.where(img_array < 150, 0, img_array)\n",
    "plt.imshow(img_array, cmap=\"gray\")\n",
    "img_train = img_array.reshape(1, -1).astype(\"float32\")  / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Распознанная цифра: 8\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_train)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(\"Распознанная цифра:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "global-cKEoLTwX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
